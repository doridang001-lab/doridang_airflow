"""
ìµœì¢… ë³‘í•© ë°ì´í„° ê²€ì¦ í•¨ìˆ˜
"""
import pandas as pd


def validate_final_join(**context):
    """ìµœì¢… ë³‘í•© ë°ì´í„° ê²€ì¦"""
    ti = context['task_instance']
    
    final_path = ti.xcom_pull(
        task_ids='fin_left_join_orders_now_toorder_history',
        key='joined_orders_now_toorder_history_path'
    )
    
    if not final_path:
        print("[âŒ ì˜¤ë¥˜] ìµœì¢… ë°ì´í„° ì—†ìŒ")
        return "ê²€ì¦ ì‹¤íŒ¨"
    
    final_df = pd.read_parquet(final_path)
    
    # 1. ê¸°ë³¸ í†µê³„
    print("\n" + "="*70)
    print("ğŸ” ìµœì¢… ë°ì´í„° ê²€ì¦")
    print("="*70)
    print(f"âœ… í–‰ ìˆ˜: {len(final_df):,}í–‰")
    print(f"âœ… ì—´ ìˆ˜: {len(final_df.columns):,}ì»¬ëŸ¼")
    
    # 2. ì£¼ë¬¸ ê¸°ì¤€ í™•ì¸ (left joinì´ë¯€ë¡œ ì£¼ë¬¸ í–‰ ìˆ˜ ìœ ì§€)
    orders_path = ti.xcom_pull(
        task_ids='load_sales_daily_orders_alerts',
        key='sales_daily_orders_alerts_path'
    )
    if orders_path:
        orders_df = pd.read_parquet(orders_path)
        print(f"\nğŸ“Š ì£¼ë¬¸ ë°ì´í„° (LEFT ê¸°ì¤€)")
        print(f"   - ì›ë³¸ í–‰ ìˆ˜: {len(orders_df):,}í–‰")
        print(f"   - ìµœì¢… í–‰ ìˆ˜: {len(final_df):,}í–‰")
        print(f"   - ìœ ì§€ìœ¨: {(len(final_df)/len(orders_df)*100):.1f}%")
        
        if len(final_df) != len(orders_df):
            print(f"   âš ï¸  ê²½ê³ : left joinì´ë¯€ë¡œ í–‰ ìˆ˜ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤")
    
    # 3. ì¼ë³„ ê·¸ë£¹í™” í™•ì¸
    if 'order_daily' in final_df.columns:
        daily_groups = final_df['order_daily'].nunique()
        print(f"\nğŸ“… ì¼ë³„ ê·¸ë£¹í™”")
        print(f"   - ê³ ìœ  ë‚ ì§œ: {daily_groups}ê°œ")
        
        stores_per_day = final_df.groupby('order_daily')['ë§¤ì¥ëª…'].nunique()
        print(f"   - ë‚ ì§œë³„ í‰ê·  ë§¤ì¥: {stores_per_day.mean():.1f}ê°œ")
        print(f"   - ë‚ ì§œë³„ ìµœëŒ€ ë§¤ì¥: {stores_per_day.max():.0f}ê°œ")
    
    # 4. ì¤‘ë³µ í™•ì¸ (left joinì´ë¯€ë¡œ ì¼ë¶€ ì¤‘ë³µì€ ì •ìƒ)
    if 'order_daily' in final_df.columns and 'ë§¤ì¥ëª…' in final_df.columns:
        daily_store_dup = final_df.duplicated(subset=['order_daily', 'ë§¤ì¥ëª…']).sum()
        print(f"\nğŸ”¢ ì¤‘ë³µ í™•ì¸ (order_daily + ë§¤ì¥ëª…)")
        print(f"   - ì¤‘ë³µ í–‰: {daily_store_dup}ê°œ")
        if daily_store_dup == 0:
            print(f"   âœ… ì •ìƒ: ì¼ë³„/ë§¤ì¥ë³„ë¡œ ê³ ìœ í•¨ (left join ê¸°ì¤€)")
        else:
            print(f"   âš ï¸  ì£¼ì˜: left joinì´ë¯€ë¡œ ì¼ë¶€ ì¤‘ë³µì€ ì •ìƒì…ë‹ˆë‹¤")
    
    # 5. null ê°’ í™•ì¸
    print(f"\nâ“ Null ê°’ í˜„í™© (ìƒìœ„ 10ê°œ ì»¬ëŸ¼)")
    null_stats = final_df.isnull().sum().sort_values(ascending=False).head(10)
    for col, cnt in null_stats.items():
        pct = (cnt / len(final_df) * 100)
        if pct > 50:
            symbol = "âš ï¸ "
        elif pct > 10:
            symbol = "ğŸ“Œ "
        else:
            symbol = "âœ… "
        print(f"   {symbol} {col}: {cnt:,}ê°œ ({pct:.1f}%)")
    
    # 6. ì»¬ëŸ¼ ëª©ë¡
    print(f"\nğŸ“‹ ìµœì¢… ì»¬ëŸ¼ ëª©ë¡ ({len(final_df.columns)}ê°œ)")
    cols = final_df.columns.tolist()
    for i, col in enumerate(cols, 1):
        print(f"   {i:2d}. {col}")
    
    print("\n" + "="*70)
    print("âœ… ê²€ì¦ ì™„ë£Œ\n")
    
    return f"ê²€ì¦ ì™„ë£Œ: {len(final_df):,}í–‰ Ã— {len(final_df.columns):,}ì»¬ëŸ¼"
