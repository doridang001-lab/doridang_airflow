
"""
ì¿ íŒ¡ì´ì¸  ì¿ í° ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
"""
import pandas as pd
import numpy as np
from pathlib import Path

from modules.load.load_df_glob import load_data
from modules.transform.utility.paths import TEMP_DIR, LOCAL_DB, COLLECT_DB


# ============================================================
# ê²½ë¡œ ì„¤ì •
# ============================================================
PATH_COUPON = COLLECT_DB / "ì „ëµê¸°íšíŒ€_ìˆ˜ì§‘" / "coupangeats_coupon_*.csv"
PATH_BACKUP = "/opt/airflow/download/ì—…ë¡œë“œ_temp"


# ============================================================
# ë²”ìš© ì¬ì—…ë¡œë“œ ë¡œë” (í•µì‹¬ í•¨ìˆ˜)
# ============================================================
def load_reupload_generic(
    file_pattern: str,
    xcom_key: str,
    search_paths: list,
    fallback_func: callable,
    dedup_key: list = None,
    **context
):
    """
    ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤ë§ˆíŠ¸ ë¡œë”
    
    Args:
        file_pattern: íŒŒì¼ íŒ¨í„´ (ì˜ˆ: 'coupangeats_coupon_*.csv')
        xcom_key: XCom ì €ì¥ í‚¤
        search_paths: ê²€ìƒ‰í•  ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        fallback_func: íŒŒì¼ ì—†ì„ ë•Œ í˜¸ì¶œí•  í•¨ìˆ˜
        dedup_key: ì¤‘ë³µ ì œê±° í‚¤ (ì›ë³¸ ì»¬ëŸ¼ ê¸°ì¤€)
    """
    all_files = []
    
    # ëª¨ë“  ê²½ë¡œì—ì„œ íŒŒì¼ ì°¾ê¸°
    for path_str in search_paths:
        search_path = Path(path_str)
        if search_path.exists():
            found_files = list(search_path.glob(file_pattern))
            if found_files:
                print(f"[{Path(path_str).name}] {len(found_files)}ê°œ íŒŒì¼ ë°œê²¬")
                all_files.extend(found_files)
    
    if all_files:
        print(f"[âœ… ì¬ì‚¬ìš©] ì´ {len(all_files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        # ğŸ¯ ì¤‘ë³µ íŒŒì¼ ì œê±° (íŒŒì¼ëª… ê¸°ì¤€, ìµœì‹  ìš°ì„ )
        unique_files = {}
        for f in all_files:
            fname = f.name
            if fname not in unique_files or f.stat().st_mtime > unique_files[fname].stat().st_mtime:
                unique_files[fname] = f
        
        file_paths = list(unique_files.values())
        print(f"[ì¤‘ë³µ ì œê±°] {len(file_paths)}ê°œ íŒŒì¼ ì‚¬ìš©")
        
        # load_data í˜¸ì¶œ
        return load_data(
            file_path=file_paths,
            xcom_key=xcom_key,
            use_glob=False,
            dedup_key=dedup_key,
            add_source_info=False,
            **context
        )
    else:
        print(f"[ğŸ”„ ìƒˆë¡œ ë¡œë“œ] ëª¨ë“  ê²½ë¡œì—ì„œ íŒŒì¼ ì—†ìŒ â†’ fallback í•¨ìˆ˜ í˜¸ì¶œ")
        return fallback_func(**context)


# ============================================================
# ì¿ íŒ¡ì´ì¸  ì¿ í° ë°ì´í„° ë¡œë”
# ============================================================
def load_reupload_coupang_coupon(**context):
    """ì¿ íŒ¡ì´ì¸  ì¿ í° ë°ì´í„° ìŠ¤ë§ˆíŠ¸ ë¡œë”"""
    return load_reupload_generic(
        file_pattern='coupangeats_coupon_*.csv',
        xcom_key='coupang_coupon_path',
        search_paths=[
            PATH_BACKUP,
            str(COLLECT_DB / "ì „ëµê¸°íšíŒ€_ìˆ˜ì§‘")
        ],
        fallback_func=load_coupang_coupon_df,
        dedup_key=['store_id', 'ë‚ ì§œ'],
        **context
    )


def load_coupang_coupon_df(**context):
    """ì¿ íŒ¡ì´ì¸  ì¿ í° ì›ë³¸ ë¡œë“œ (fallbackìš©)"""
    return load_data(
        file_path=PATH_COUPON,
        xcom_key='coupang_coupon_path',
        use_glob=True,
        dedup_key=['store_id', 'ë‚ ì§œ'],
        add_source_info=False,
        **context
    )


# ============================================================
# ì „ì²˜ë¦¬ í•¨ìˆ˜ (í•„ìš”ì‹œ ì¶”ê°€)
# ============================================================
def preprocess_coupang_coupon_df(**context):
    """ì¿ íŒ¡ì´ì¸  ì¿ í° ë°ì´í„° ì „ì²˜ë¦¬"""
    ti = context['task_instance']
    parquet_path = ti.xcom_pull(task_ids='load_coupang_coupon', key='coupang_coupon_path')
    
    if not parquet_path:
        ti.xcom_push(key='processed_coupang_coupon_path', value=None)
        return "0ê±´ (ì…ë ¥ ë°ì´í„° ì—†ìŒ)"
    
    df = pd.read_parquet(parquet_path)
    
    # ============================================================
    # ì „ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
    # ============================================================
    # ì˜ˆì‹œ:
    # df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
    # df['stores_name'] = "ë„ë¦¬ë‹¹ " + df['ë§¤ì¥ëª…']
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    # col = ['ë‚ ì§œ', 'stores_name', 'store_id', 'ì¿ í°ìˆ˜', ...]
    # df = df[col]
    
    output_path = TEMP_DIR / f"processed_coupang_coupon_{context['ds_nodash']}.parquet"
    TEMP_DIR.mkdir(exist_ok=True, parents=True)
    df.to_parquet(output_path, index=False)
    
    ti.xcom_push(key='processed_coupang_coupon_path', value=str(output_path))
    return f"ì „ì²˜ë¦¬: {len(df):,}í–‰"