"""
íˆ¬ì˜¤ë” ë¦¬ë·° ë¡œë“œ DAG

ğŸ”„ ë‘ ê°€ì§€ ëª¨ë“œ:
1. ì •ê¸° ì‹¤í–‰ (ì›”/ìˆ˜ 10:45): ëª¨ë“  ì›ë³¸ ë°ì´í„° ìƒˆë¡œ ë¡œë“œ í›„ JOIN
2. ì¬ì—…ë¡œë“œ ëª¨ë“œ: ì´ì „ì˜ ë°°ë¯¼/í† ë” ê³„ì‚° ê²°ê³¼ ì¬ì‚¬ìš©, ìˆ˜ì •ëœ ë§¤ì¶œ ë°ì´í„°ë§Œ ìƒˆë¡œ JOIN
   - "ì—…ë¡œë“œ_temp" + "ì›ë“œë¼ì´ë¸Œ"ì˜ ì´ì „ íŒŒì¼ë“¤ í™œìš©
   - ëˆ„ë½ëœ ë°ì´í„° ë³´ì • ì‹œ ì‚¬ìš©
"""
import glob
import pendulum
import pandas as pd
import os
from pathlib import Path
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.exceptions import AirflowException

import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
# íŒŒì¼ëª…
filename = os.path.basename(__file__)

# ì¬ì—…ë¡œë“œ í•¨ìˆ˜ import (ìŠ¤ë§ˆíŠ¸ ë¡œë”©)

from modules.transform.pipelines.sales_store_amount_join_validator import validate_final_join
from modules.load.load_df_glob import cleanup_collected_csvs, move_download_files
from modules.transform.utility.paths import LOCAL_DB, COLLECT_DB
from modules.transform.pipelines.market import load_reupload_generic, load_reupload_bcoupang_coupon_df, load_coupang_coupon_df



# DAG ì •ì˜
with DAG(
    dag_id=filename.replace('.py', ''),
    schedule="45 10 * * 1,3",  # ë§¤ì£¼ ì›”, ìˆ˜ 10ì‹œ 45ë¶„ ì‹¤í–‰
    start_date=pendulum.datetime(2023, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=['02_sales','crawling', 'toorder'],
) as dag:
    # ============================================================
    # ìŠ¤ë§ˆíŠ¸ ë¡œë”© íƒœìŠ¤í¬ (ìë™ ê°ì§€ ë°©ì‹)
    # ì—…ë¡œë“œ_temp + ì›ë“œë¼ì´ë¸Œì—ì„œ íŒŒì¼ ì°¾ê¸°
    # ì´ì „ íŒŒì¼ ìˆìœ¼ë©´ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ ìƒˆë¡œ ë¡œë“œ
    # ============================================================
    
    # ì¿ íŒ¡ df ë³‘í•©
    load_reupload_coupang_coupon_task = PythonOperator(
        task_id='load_reupload_coupang_coupon_df',
        python_callable=load_reupload_bcoupang_coupon_df,
    )

load_reupload_coupang_coupon_task