"""
ì§ì› ì •ë³´ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê°€ì ¸ì˜¤ëŠ” DAG

Google Sheet â†’ sales_employee.csv (í”Œë«í¼ë³„ í–‰ ë¶„ë¦¬)
"""

import pendulum
import pandas as pd
import os
import re
from pathlib import Path
from airflow import DAG
from airflow.operators.python import PythonOperator

import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

filename = os.path.basename(__file__)

from modules.transform.utility.paths import LOCAL_DB
from modules.extract.extract_gsheet import extract_gsheet

# ì„¤ì •
DEFAULT_CREDENTIALS_PATH = r"/opt/airflow/config/rare-ethos-483607-i5-45c9bec5b193.json"
EMPLOYEE_GSHEET_URL = "https://docs.google.com/spreadsheets/d/1a6-20U1-FYCQEfbOOVSDG3M0q6G2me5f/edit"
EMPLOYEE_SHEET_NAME = None
EMPLOYEE_CSV_PATH = LOCAL_DB / 'ì˜ì—…ê´€ë¦¬ë¶€_DB' / 'sales_employee.csv'


def parse_address(address_str):
    """ì£¼ì†Œë¥¼ ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê´‘ì—­/ì‹œêµ°êµ¬/ìë©´ë™ìœ¼ë¡œ íŒŒì‹±"""
    if pd.isna(address_str) or str(address_str).strip() == '':
        return '', '', ''
    
    addr = str(address_str).strip()
    
    # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ split
    parts = addr.split()
    
    sido = parts[0] if len(parts) > 0 else ''
    sigungu = parts[1] if len(parts) > 1 else ''
    dong = parts[2] if len(parts) > 2 else ''
    
    return sido, sigungu, dong


def load_employee_from_gsheet(**context):
    print(f"\n{'='*60}")
    print(f"[êµ¬ê¸€ì‹œíŠ¸] ì§ì› ì •ë³´ ë¡œë“œ ì‹œì‘")
    
    # 1ï¸âƒ£ Google Sheets ì½ê¸°
    try:
        df_raw = extract_gsheet(
            url=EMPLOYEE_GSHEET_URL,
            sheet_name=EMPLOYEE_SHEET_NAME,
            credentials_path=DEFAULT_CREDENTIALS_PATH,
        )
        
        # í—¤ë” ìë™ ê°ì§€
        header_row_idx = None
        for idx, row in df_raw.iterrows():
            if any(str(v).strip() == 'í˜¸ì ' for v in row.tolist()):
                header_row_idx = idx
                break

        if header_row_idx is None:
            return "ë¡œë“œ ì‹¤íŒ¨: í—¤ë” íƒìƒ‰ ì‹¤íŒ¨"

        raw_header = [str(col).strip().replace('\n', '') if pd.notna(col) else '' for col in df_raw.iloc[header_row_idx].tolist()]
        first_nonempty = next((i for i, h in enumerate(raw_header) if h), 0)
        
        header = raw_header[first_nonempty:]
        data = df_raw.iloc[header_row_idx + 1:, first_nonempty:].copy()
        data.columns = header
        df = data.reset_index(drop=True)
        
        print(f"[ë¡œë“œ] ì„±ê³µ: {len(df):,}ê±´")
        
    except Exception as e:
        print(f"[ì—ëŸ¬] {e}")
        return f"ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
    
    # 2ï¸âƒ£ ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = [str(col).strip().replace('\n', '') for col in df.columns]
    
    # 3ï¸âƒ£ í˜¸ì  í•„í„°ë§
    if 'í˜¸ì ' not in df.columns:
        return "ë¡œë“œ ì‹¤íŒ¨: 'í˜¸ì ' ì»¬ëŸ¼ ì—†ìŒ"
    
    df = df[df['í˜¸ì '].notna()].copy()
    df = df[df['í˜¸ì '].astype(str).str.strip() != ''].copy()
    df = df[~df['í˜¸ì '].astype(str).str.contains('~', na=False)].copy()
    
    print(f"[í•„í„°ë§] {len(df):,}ê±´")
    
    # 4ï¸âƒ£ ì»¬ëŸ¼ëª… ë§¤í•‘
    column_mapping = {
        'ì˜¤í”ˆìˆœì„œ': 'ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ': 'í˜¸ì ', 'ë§¤ì¥ëª…': 'ë§¤ì¥ëª…',
        'ì‚¬ì—…ì ë²ˆí˜¸': 'ì‚¬ì—…ìë²ˆí˜¸', 'ì ì£¼ëª…': 'ì ì£¼ëª…',
        'ë‹´ë‹¹ S.V': 'ë‹´ë‹¹ì', 'ë‹´ë‹¹ SV': 'ë‹´ë‹¹SV',
        'ë§ˆì¼€íŒ…ë¹„ ìˆ˜ë ¹ (110ë§Œ)': 'ë§ˆì¼€íŒ…ë¹„ìˆ˜ë ¹',
        'ê³„ì•½ì²´ê²°ì¼': 'ê³„ì•½ì²´ê²°ì¼', 'ì‹¤ì˜¤í”ˆì¼': 'ì‹¤ì˜¤í”ˆì¼',
        'íì—…ì¼(ì–‘ë„ì–‘ìˆ˜ í¬í•¨)': 'íì—…ì¼', 'ìƒë…„ì›”ì¼(880808)': 'ìƒë…„ì›”ì¼',
        'ì „í™”ë²ˆí˜¸(mobile)': 'ì „í™”ë²ˆí˜¸', 'ì£¼ì†Œ': 'ìƒì„¸ì£¼ì†Œ',
        'ë°°ë‹¬ì˜ ë¯¼ì¡±ID': 'ë°°ë¯¼ID', 'ë°°ë‹¬ì˜ ë¯¼ì¡±PW': 'ë°°ë¯¼PW',
        'ìš”ê¸°ìš”ID': 'ìš”ê¸°ìš”ID', 'ìš”ê¸°ìš”PW': 'ìš”ê¸°ìš”PW',
        'ì¿ íŒ¡ì´ì¸ ID': 'ì¿ íŒ¡ID', 'ì¿ íŒ¡ì´ì¸ PW': 'ì¿ íŒ¡PW',
        'ë•¡ê²¨ìš”ID': 'ë•¡ê²¨ìš”ID', 'ë•¡ê²¨ìš”PW': 'ë•¡ê²¨ìš”PW',
        'í† ë” ID': 'í† ë”ID', 'í† ë”PW': 'í† ë”PW',
        'ë„¤ì´ë²„ ID': 'ë„¤ì´ë²„ID', 'ë„¤ì´ë²„ pw': 'ë„¤ì´ë²„PW'
    }
    
    rename_dict = {old: new for old, new in column_mapping.items() if old in df.columns}
    if rename_dict:
        df = df.rename(columns=rename_dict)
    
    # 5ï¸âƒ£ email ë§¤í•‘
    email_mapping = {
        'ê¹€ë•ê¸° ê³¼ì¥': 'kdk1402@kakao.com',
        'ì‹¬ì„±ì¤€ ì´ì‚¬': 'a17019@kakao.com',
        'ì´ë³‘ë‘ ê³¼ì¥': 'byoungd201@kakao.com',
        'í™©ëŒ€ì„± ëŒ€ë¦¬': 'gjddkemf@kakao.com',
        'ê¹€ëŒ€ì§„ íŒ€ì¥': 'sanbogaja81@kakao.com',
    }

    # ë‹´ë‹¹ì ì»¬ëŸ¼ ì²˜ë¦¬
    if 'ë‹´ë‹¹ì' not in df.columns and 'ë‹´ë‹¹SV' in df.columns:
        df['ë‹´ë‹¹ì'] = df['ë‹´ë‹¹SV']
    
    if 'ë‹´ë‹¹ì' in df.columns:
        if 'ë‹´ë‹¹SV' in df.columns:
            empty_mask = df['ë‹´ë‹¹ì'].astype(str).str.strip() == ''
            df.loc[empty_mask, 'ë‹´ë‹¹ì'] = df.loc[empty_mask, 'ë‹´ë‹¹SV']
        
        df['ë‹´ë‹¹ì'] = (df['ë‹´ë‹¹ì']
                      .astype(str)
                      .str.replace(r'[\s\u3000\xa0\t\n\r]+', ' ', regex=True)
                      .str.strip()
                      .replace('nan', ''))
        
        print(f"\n[ë‹´ë‹¹ì ëª©ë¡]:")
        for mgr in sorted(df['ë‹´ë‹¹ì'].unique()):
            if mgr:
                count = (df['ë‹´ë‹¹ì'] == mgr).sum()
                status = "âœ“" if mgr in email_mapping else "âœ—"
                print(f"  {status} '{mgr}' ({count}ê±´)")
        
        # email ì²˜ë¦¬
        base_email = None
        for col in ['email', 'ì´ë©”ì¼']:
            if col in df.columns:
                base_email = df[col].astype(str).fillna('').str.strip()
                print(f"\n[ê¸°ì¡´ email ì»¬ëŸ¼] '{col}' ë°œê²¬")
                break
        
        if base_email is None:
            base_email = pd.Series([''] * len(df))
            print(f"\n[email ì»¬ëŸ¼] ìƒˆë¡œ ìƒì„±")
        
        df['email'] = base_email
        needs_map = (df['email'].str.strip() == '') & (df['ë‹´ë‹¹ì'] != '')
        df.loc[needs_map, 'email'] = df.loc[needs_map, 'ë‹´ë‹¹ì'].map(email_mapping).fillna('')
        
        mapped = (df['email'].str.strip() != '').sum()
        valid = df['email'].str.contains('@', na=False).sum()
        
        print(f"\n[email ê²°ê³¼]")
        print(f"  - ì´ ì±„ì›Œì§: {mapped}/{len(df)}ê±´")
        print(f"  - @ í¬í•¨: {valid}/{len(df)}ê±´")
    
    # 6ï¸âƒ£ ì£¼ì†Œ íŒŒì‹± (ê´‘ì—­/ì‹œêµ°êµ¬/ìë©´ë™)
    if 'ìƒì„¸ì£¼ì†Œ' in df.columns:
        print(f"\n[ì£¼ì†Œ íŒŒì‹±] ì‹œì‘...")
        df[['ê´‘ì—­', 'ì‹œêµ°êµ¬', 'ìë©´ë™']] = df['ìƒì„¸ì£¼ì†Œ'].apply(
            lambda x: pd.Series(parse_address(x))
        )
        print(f"[ì£¼ì†Œ íŒŒì‹±] ì™„ë£Œ")
    
    # 7ï¸âƒ£ í”Œë«í¼ë³„ë¡œ í–‰ ë¶„ë¦¬ (unpivot)
    print(f"\n[í”Œë«í¼ ë¶„ë¦¬] ì‹œì‘...")
    
    platform_mapping = {
        'ë°°ë‹¬ì˜ ë¯¼ì¡±': ('ë°°ë¯¼ID', 'ë°°ë¯¼PW'),
        'ìš”ê¸°ìš”': ('ìš”ê¸°ìš”ID', 'ìš”ê¸°ìš”PW'),
        'ì¿ íŒ¡ì´ì¸ ': ('ì¿ íŒ¡ID', 'ì¿ íŒ¡PW'),
        'ë•¡ê²¨ìš”': ('ë•¡ê²¨ìš”ID', 'ë•¡ê²¨ìš”PW'),
        'í† ë”': ('í† ë”ID', 'í† ë”PW'),
    }
    
    # ê¸°ë³¸ ì •ë³´ ì»¬ëŸ¼ (í”Œë«í¼ ë¬´ê´€)
    base_columns = ['ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ', 'ë§¤ì¥ëª…', 'ì‚¬ì—…ìë²ˆí˜¸', 'ì ì£¼ëª…', 'ë‹´ë‹¹ì', 
                    'ì‹¤ì˜¤í”ˆì¼', 'ìƒì„¸ì£¼ì†Œ', 'ê´‘ì—­', 'ì‹œêµ°êµ¬', 'ìë©´ë™', 'email']
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    base_columns = [col for col in base_columns if col in df.columns]
    
    rows = []
    for _, row in df.iterrows():
        for platform, (id_col, pw_col) in platform_mapping.items():
            # IDì™€ PW ì»¬ëŸ¼ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
            if id_col not in df.columns or pw_col not in df.columns:
                continue
            
            account_id = str(row[id_col]).strip() if pd.notna(row[id_col]) else ''
            account_pw = str(row[pw_col]).strip() if pd.notna(row[pw_col]) else ''
            
            # IDê°€ ë¹„ì–´ìˆìœ¼ë©´ í•´ë‹¹ í”Œë«í¼ í–‰ ìƒì„± ì•ˆ í•¨
            if account_id == '' or account_id == 'nan':
                continue
            
            # ë‹´ë‹¹ì ê²€ì¦: ë¹ˆ ê°’ì´ë©´ í•´ë‹¹ í–‰ ìŠ¤í‚µ
            manager = str(row['ë‹´ë‹¹ì']).strip() if pd.notna(row['ë‹´ë‹¹ì']) else ''
            if manager == '' or manager == 'nan':
                continue
            
            # ê¸°ë³¸ ì •ë³´ ë³µì‚¬
            new_row = {col: row[col] for col in base_columns}
            
            # í”Œë«í¼ ì •ë³´ ì¶”ê°€
            new_row['í”Œë«í¼'] = platform
            new_row['ê³„ì •ID'] = account_id
            new_row['ê³„ì •PW'] = account_pw
            
            rows.append(new_row)
    
    df_final = pd.DataFrame(rows)
    
    print(f"[í”Œë«í¼ ë¶„ë¦¬] ì™„ë£Œ: {len(df)}ê°œ ë§¤ì¥ â†’ {len(df_final)}ê°œ í–‰")
    
    # 8ï¸âƒ£ collected_at ì¶”ê°€
    df_final['collected_at'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')
    
    # 9ï¸âƒ£ ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    final_columns = ['ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ', 'ë§¤ì¥ëª…', 'ì‚¬ì—…ìë²ˆí˜¸', 'ì ì£¼ëª…', 'ë‹´ë‹¹ì', 
                     'ì‹¤ì˜¤í”ˆì¼', 'ìƒì„¸ì£¼ì†Œ', 'ê´‘ì—­', 'ì‹œêµ°êµ¬', 'ìë©´ë™', 
                     'í”Œë«í¼', 'ê³„ì •ID', 'ê³„ì •PW', 'collected_at', 'email']
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    final_columns = [col for col in final_columns if col in df_final.columns]
    df_final = df_final[final_columns]
    
    # ë‹´ë‹¹ì í•„í„°ë§ (null, ë¹ˆ ë¬¸ìì—´, 'nan' ì œì™¸)
    if 'ë‹´ë‹¹ì' in df_final.columns:
        df_final = df_final[
            (df_final["ë‹´ë‹¹ì"].notna()) & 
            (df_final["ë‹´ë‹¹ì"].astype(str).str.strip() != '') &
            (df_final["ë‹´ë‹¹ì"].astype(str) != 'nan')
        ]
        print(f"[í•„í„°ë§] ë‹´ë‹¹ì ì—†ëŠ” í–‰ ì œì™¸ í›„: {len(df_final):,}ê±´")
    
    # ğŸ”Ÿ CSV ì €ì¥
    EMPLOYEE_CSV_PATH.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        df_final.to_csv(EMPLOYEE_CSV_PATH, index=False, encoding='utf-8-sig')
        file_size = EMPLOYEE_CSV_PATH.stat().st_size / 1024
        
        print(f"\n[ì €ì¥] âœ… ì™„ë£Œ")
        print(f"  - ê²½ë¡œ: {EMPLOYEE_CSV_PATH}")
        print(f"  - í–‰: {len(df_final):,}ê±´ / ì—´: {len(df_final.columns)}ê°œ")
        print(f"  - í¬ê¸°: {file_size:.2f} KB")
        
        # í”Œë«í¼ë³„ í†µê³„
        print(f"\n[í”Œë«í¼ë³„ í†µê³„]")
        for platform, count in df_final['í”Œë«í¼'].value_counts().items():
            print(f"  - {platform}: {count}ê°œ")
        
        print(f"{'='*60}\n")
        
        return f"âœ… ë¡œë“œ ì™„ë£Œ: {len(df_final):,}ê°œ í–‰ (í”Œë«í¼ë³„ ë¶„ë¦¬)"
        
    except Exception as e:
        print(f"[ì—ëŸ¬] ì €ì¥ ì‹¤íŒ¨: {e}")
        return f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"


with DAG(
    dag_id=filename.replace('.py', ''),
    description='ì§ì›/ë§¤ì¥ ì •ë³´ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê°€ì ¸ì™€ í”Œë«í¼ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ CSVë¡œ ì €ì¥',
    schedule="0 10 * * 1",  # ë§¤ì£¼ ì›” 10:00
    start_date=pendulum.datetime(2023, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=['01_employee', 'gsheet', 'load'],
) as dag:
    
    load_employee_task = PythonOperator(
        task_id='load_employee_from_gsheet',
        python_callable=load_employee_from_gsheet,
    )
    
    load_employee_task