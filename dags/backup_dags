"""
DB íŒŒì¼ ë³‘í•© íŒŒì´í”„ë¼ì¸ DAG

ğŸ“‹ ëª©ì :
  - í† ë” ë¦¬ë·° ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë¡œë“œí•˜ì—¬ ë³‘í•©
  - CSV/ì—‘ì…€ íŒŒì¼ì„ ìë™ìœ¼ë¡œ íƒì§€í•˜ê³  ì¤‘ë³µ ì œê±°
  - ì „ì²˜ë¦¬ í›„ ë¡œì»¬ DBì— CSVë¡œ ì €ì¥

ğŸ”„ ì²˜ë¦¬ ë‹¨ê³„:
  1. ë°ì´í„° ë¡œë“œ: CSV ìš°ì„ , ì—†ìœ¼ë©´ ì—‘ì…€ ë¡œë“œ
  2. ì „ì²˜ë¦¬: ê·¸ë£¹í™”, ì§‘ê³„, ë§¤ì¥ëª… ì •ë¦¬, ID ìƒì„±
  3. CSV ì €ì¥: ë¡œì»¬ DBì— ìµœì¢… ê²°ê³¼ ì €ì¥

ğŸ“‚ ë°ì´í„° ì†ŒìŠ¤:
  - /opt/airflow/download/ì—…ë¡œë“œ_temp/toorder_review_*.csv
  - ì›ë“œë¼ì´ë¸Œ/ì˜ì—…ê´€ë¦¬ë¶€_ìˆ˜ì§‘/toorder_review_*.csv
  - /opt/airflow/download/toorder_review_doridang1_*.xlsx

â° ìŠ¤ì¼€ì¤„: ë§¤ì£¼ ì›”, ìˆ˜ 11ì‹œ ì‹¤í–‰
"""
import pendulum
import os
from airflow import DAG
from airflow.operators.python import PythonOperator
from modules.transform.utility.io2 import load_and_concat_csv
# í•¨ìˆ˜ import
# ============================================================
# ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤:
# 
# 1. load_reupload_toorder_review(**context)
#    - í† ë” ë¦¬ë·° ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œ (CSV ìš°ì„ , ì—‘ì…€ ëŒ€ì²´)
#    - XComìœ¼ë¡œ 'toorder_review_path' ë°˜í™˜
# 
# 2. preprocess_toorder_review_df(input_task_id, input_xcom_key, output_xcom_key, **context)
#    - í† ë” ë¦¬ë·° ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ (ê·¸ë£¹í™”, ì§‘ê³„, ID ìƒì„±)
#    - XComìœ¼ë¡œ ì²˜ë¦¬ëœ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
# 
# 3. fin_save_to_csv(input_task_id, input_xcom_key, output_filename, **context)
#    - Parquet ë°ì´í„°ë¥¼ ë¡œì»¬ DBì— CSVë¡œ ì €ì¥
#    - ì¤‘ë³µ ì œê±° ë° ë°±ì—… ìë™ ì²˜ë¦¬
# ============================================================
from modules.transform.pipelines.db_file_merge_pipeline import (
    load_df as load_reupload_toorder_review,
    preprocess_toorder_review_df,
    fin_save_to_csv,
    load_baemin_ad_change_history_df,
    preprocess_baemin_ad_change_history_df,
    baemin_ad_change_history_save_to_csv
)

# ==================================================
# DAG ì •ì˜
# ==================================================
filename = os.path.basename(__file__)

with DAG(
    dag_id=filename.replace('.py', ''),
    schedule="0 11 * * 1,3",  # ë§¤ì£¼ ì›”, ìˆ˜ 11ì‹œ 00ë¶„ ì‹¤í–‰
    start_date=pendulum.datetime(2023, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=['02_sales', 'crawling', 'coupang'],
) as dag:
    # ============================================================
    # Task 1: í† ë” ë¦¬ë·° ë°ì´í„° ë¡œë“œ
    # ============================================================
    # ğŸ“¥ ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ìë™ìœ¼ë¡œ íŒŒì¼ íƒìƒ‰ ë° ë¡œë“œ
    # - CSV íŒŒì¼ ìš°ì„  ê²€ìƒ‰ (ë¹ ë¦„)
    # - CSV ì—†ìœ¼ë©´ ì—‘ì…€ íŒŒì¼ ê²€ìƒ‰
    # - ì¤‘ë³µ íŒŒì¼ëª…ì€ ìµœì‹  íŒŒì¼ë§Œ ì‚¬ìš©
    # 
    # ì¶œë ¥: XCom['toorder_review_path'] = parquet íŒŒì¼ ê²½ë¡œ
    task_load_reupload = PythonOperator(
        task_id='load_reupload_toorder_review',
        python_callable=load_reupload_toorder_review,
    )
    
    # ============================================================
    # Task 2: í† ë” ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬
    # ============================================================
    # ğŸ”„ ì²˜ë¦¬ ë‚´ìš©:
    # - ì»¬ëŸ¼ ì„ íƒ (date, ë§¤ì¥ëª….1, ì±„ë„, ì£¼ë¬¸ ìˆ˜, ë¦¬ë·° ìˆ˜ ë“±)
    # - ê²°ì¸¡ì¹˜ ì œê±° (ì±„ë„ì´ nullì¸ í–‰)
    # - ë‚ ì§œ/ë§¤ì¥ë³„ ê·¸ë£¹í™” ë° ì§‘ê³„ (sum, í‰ê· )
    # - Surrogate Key ìƒì„± (date + stores_name)
    # - ë§¤ì¥ëª… í‘œì¤€í™” ("ë„ë¦¬ë‹¹" ì ‘ë‘ì‚¬, ë³„ì¹­ í†µì¼)
    # 
    # ì…ë ¥: XCom['toorder_review_path'] (ì´ì „ Taskì—ì„œ)
    # ì¶œë ¥: XCom['processed_toorder_review_path'] = ì „ì²˜ë¦¬ëœ parquet ê²½ë¡œ
    task_preprocess = PythonOperator(
        task_id='preprocess_toorder_review',
        python_callable=preprocess_toorder_review_df,
        op_kwargs={
            'input_task_id': 'load_reupload_toorder_review',  # ì´ì „ Task ID
            'input_xcom_key': 'toorder_review_path',          # ì½ì„ XCom í‚¤
            'output_xcom_key': 'processed_toorder_review_path',  # ì €ì¥í•  XCom í‚¤
        }
    )
    
    # í† ë”ë¦¬ë·° csvì €ì¥   
    task_save_csv = PythonOperator(
        task_id='save_toorder_review_csv',
        python_callable=fin_save_to_csv,
        op_kwargs={
            'input_task_id': 'preprocess_toorder_review',
            'input_xcom_key': 'processed_toorder_review_path',
            'output_filename': 'toorder_review_doridang.csv',
        }
    )
    
    # ë°°ë¯¼ ê´‘ê³  ë³€ê²½ì´ë ¥ ë¡œë“œ
    task_load_baemin_ad_change_history = PythonOperator(
        task_id='load_baemin_ad_change_history',
        python_callable=load_baemin_ad_change_history_df,
    )
    # ë°°ë¯¼ ê´‘ê³  ë³€ê²½ì´ë ¥ ì „ì²˜ë¦¬
    task_preprocess_baemin_ad_change_history = PythonOperator(
        task_id='preprocess_baemin_ad_change_history',
        python_callable=preprocess_baemin_ad_change_history_df,
        op_kwargs={
            'input_task_id': 'load_baemin_ad_change_history',
            'input_xcom_key': 'baemin_ad_change_history_path',
            'output_xcom_key': 'processed_baemin_ad_change_history_path',
        }
    )
    # ë°°ë¯¼ ê´‘ê³  ë³€ê²½ì´ë ¥ csvì €ì¥
    task_baemin_ad_change_history_save_csv = PythonOperator(
        task_id='baemin_ad_change_history_save_to_csv',
        python_callable=baemin_ad_change_history_save_to_csv,
        op_kwargs={
            'input_task_id': 'preprocess_baemin_ad_change_history',
            'input_xcom_key': 'processed_baemin_ad_change_history_path',
        }
    )
        

 # Task ì˜ì¡´ì„± ì„¤ì •
task_load_reupload >> task_preprocess >> task_save_csv
task_load_baemin_ad_change_history >> task_preprocess_baemin_ad_change_history >> task_baemin_ad_change_history_save_csv