"""
êµ¬ê¸€ì‹œíŠ¸ ê°€ë§¹ì  ë¦¬ìŠ¤íŠ¸ ETL DAG

ê¸°ëŠ¥:
    1. êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ê°€ë§¹ì  ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    2. í”Œë«í¼ë³„ ê³„ì • ì •ë³´ë¡œ ë³€í™˜ (Wide â†’ Long)
    3. OneDrive CSVì— ì €ì¥
    4. ì²˜ë¦¬ ê²°ê³¼ ì´ë©”ì¼ ì „ì†¡

ì£¼ê¸°: ë§¤ì¼ 06:31
"""
from airflow import DAG
import os
import sys
import pendulum
from pathlib import Path
import pandas as pd
import datetime as dt
from airflow.operators.python import PythonOperator
from airflow.providers.smtp.operators.smtp import EmailOperator

# modules ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# í•¨ìˆ˜ ì„í¬íŠ¸
from modules.extract.extract_gsheet import extract_gsheet
from modules.load.load_onedrive import onedrive_csv_save
from modules.transform.utility.paths import ONEDRIVE_DB

filename = os.path.basename(__file__)

# CSV ì €ì¥ ê²½ë¡œ (í…ŒìŠ¤íŠ¸ìš© - ì˜ì—…ê´€ë¦¬ë¶€_DBì™€ ì¶©ëŒ ë°©ì§€)
ONEDRIVE_CSV_PATH = ONEDRIVE_DB / "temp" / "test_sales_employee.csv"
DOWNLOADS_CSV_PATH = ONEDRIVE_DB / "temp" / "test_sales_employee.csv"

# ë‹´ë‹¹ì â†’ ì´ë©”ì¼ ë§¤í•‘(í•„ìš”ì‹œ ì¶”ê°€/ìˆ˜ì •)
MANAGER_EMAIL_MAP = {
    "ì‹¬ì„±ì¤€ ì´ì‚¬" : "a17019@kakao.com",
    "ê¹€ëŒ€ì§„ íŒ€ì¥" :  "sanbogaja81@kakao.com",
    "ê¹€ë•ê¸° ê³¼ì¥" : "kdk1402@kakao.com",
    "ì´ë³‘ë‘ ê³¼ì¥" : "byoungd201@kakao.com",
    "í™©ëŒ€ì„± ëŒ€ë¦¬" : "gjddkemf@kakao.com"

}  

# ============================================================
# Task 1: êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬
# ============================================================

def transform_gsheet_data(df):
    """êµ¬ê¸€ì‹œíŠ¸ ê°€ë§¹ì  ë°ì´í„°ë¥¼ í”Œë«í¼ë³„ ê³„ì • ì •ë³´ë¡œ ë³€í™˜"""
    
    # Unnamed ì»¬ëŸ¼ ì œê±°
    if "Unnamed: 0" in df.columns:
        df = df.drop(columns=["Unnamed: 0"])
    
    # í—¤ë” í–‰ ì„¤ì • (2ë²ˆì§¸ í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©)
    header_row_idx = 1
    df.columns = df.iloc[header_row_idx]
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    df = df.rename(columns={
        'ì˜¤í”ˆ\nìˆœì„œ': 'ì˜¤í”ˆìˆœì„œ',
        'ë³€ê²½ \në‹´ë‹¹ SV': 'ë³€ê²½ë‹´ë‹¹SV'
    })
    
    # í—¤ë” ì´í›„ ë°ì´í„°ë§Œ ì¶”ì¶œ
    df = df[2:].copy()  # .copy() ì¶”ê°€
    
    # ì‚¬ì—…ì ë²ˆí˜¸ê°€ ìˆëŠ” í–‰ë§Œ í•„í„°ë§ (ìœ íš¨í•œ ë§¤ì¥ ë°ì´í„°)
    print(f"ğŸ” í•„í„°ë§ ì „: {len(df)}í–‰, ì»¬ëŸ¼: {list(df.columns)[:5]}...")
    print(f"ğŸ” ì‚¬ì—…ì ë²ˆí˜¸ ì»¬ëŸ¼ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\n{df['ì‚¬ì—…ì ë²ˆí˜¸'].head(10).tolist()}")
    print(f"ğŸ” ì‚¬ì—…ì ë²ˆí˜¸ null ê°œìˆ˜: {df['ì‚¬ì—…ì ë²ˆí˜¸'].isnull().sum()} / {len(df)}")
    print(f"ğŸ” ì‚¬ì—…ì ë²ˆí˜¸ ê³µë°± ë¬¸ìì—´ ê°œìˆ˜: {(df['ì‚¬ì—…ì ë²ˆí˜¸'].astype(str).str.strip() == '').sum()}")
    
    # nullì´ ì•„ë‹ˆê³  ê³µë°±ì´ ì•„ë‹Œ í–‰ë§Œ í•„í„°ë§
    cond1 = ~df["ì‚¬ì—…ì ë²ˆí˜¸"].isnull()
    cond2 = df["ì‚¬ì—…ì ë²ˆí˜¸"].astype(str).str.strip() != ''
    df = df.loc[cond1 & cond2].copy()
    print(f"ğŸ” í•„í„°ë§ í›„: {len(df)}í–‰")
    # ì£¼ì†Œ ì •ë¦¬: ì´ì‚¬í›„ ì£¼ì†Œ ìš°ì„ , ì—†ìœ¼ë©´ ì´ì‚¬ì „ ì£¼ì†Œ ì‚¬ìš©
    df['ìƒì„¸ì£¼ì†Œ'] = (
        df['ì£¼ì†Œ'].astype(str)
        .str.replace('\r', ' ', regex=False)  # ê°œí–‰ ì œê±°
        .str.replace('\n', ' ', regex=False)
        .str.replace('&gt;', '>', regex=False)  # HTML íŠ¹ìˆ˜ë¬¸ì
        .str.extract(r'\(ì´ì‚¬í›„ ì£¼ì†Œ\)\s*(.+)', expand=False)  # ì´ì‚¬í›„ ì£¼ì†Œ ì¶”ì¶œ
        .fillna(  # ì—†ìœ¼ë©´ ì´ì‚¬ì „ ì£¼ì†Œ ì‚¬ìš©
            df['ì£¼ì†Œ'].astype(str)
            .str.replace(r'\(ì´ì‚¬ì „ ì£¼ì†Œ\)\s*', '', regex=True)
            .str.replace('\r', ' ', regex=False)
            .str.replace('\n', ' ', regex=False)
            .str.replace('&gt;', '>', regex=False)
        )
        .str.strip()
    )

    # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ (ë³µì‚¬ë³¸ ìƒì„±ìœ¼ë¡œ SettingWithCopyWarning ë°©ì§€)
    df_col = [
        'ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ', 'ë§¤ì¥ëª…', 'ì‚¬ì—…ì ë²ˆí˜¸', 'ì ì£¼ëª…', 'ë³€ê²½ë‹´ë‹¹SV', 'ì‹¤ì˜¤í”ˆì¼', 'ìƒì„¸ì£¼ì†Œ',
        'ë°°ë‹¬ì˜ ë¯¼ì¡±ID', 'ë°°ë‹¬ì˜ ë¯¼ì¡±PW', 'ìš”ê¸°ìš”ID', 'ìš”ê¸°ìš”PW', 'ì¿ íŒ¡ì´ì¸ ID', 'ì¿ íŒ¡ì´ì¸ PW',
        'ë•¡ê²¨ìš”ID', 'ë•¡ê²¨ìš”PW', 'í† ë” ID', 'í† ë”PW', 'ë„¤ì´ë²„ ID', 'ë„¤ì´ë²„ pw'
    ]
    gsheet_store_list = df[df_col].copy()  # .copy() ì¶”ê°€
    
    # ì£¼ì†Œì—ì„œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ
    gsheet_store_list["ê´‘ì—­"] = gsheet_store_list['ìƒì„¸ì£¼ì†Œ'].str.split(' ').str[0].str[:2]
    gsheet_store_list["ì‹œêµ°êµ¬"] = gsheet_store_list['ìƒì„¸ì£¼ì†Œ'].str.split(' ').str[1]
    gsheet_store_list["ìë©´ë™"] = gsheet_store_list['ìƒì„¸ì£¼ì†Œ'].str.split(' ').str[2]
    
    # Wide â†’ Long í˜•ì‹ ë³€í™˜: í”Œë«í¼ë³„ ê³„ì •ì„ ê° í–‰ìœ¼ë¡œ ë¶„ë¦¬
    platform_cols = {
        'ë°°ë‹¬ì˜ ë¯¼ì¡±': ('ë°°ë‹¬ì˜ ë¯¼ì¡±ID', 'ë°°ë‹¬ì˜ ë¯¼ì¡±PW'),
        'ìš”ê¸°ìš”': ('ìš”ê¸°ìš”ID', 'ìš”ê¸°ìš”PW'),
        'ì¿ íŒ¡ì´ì¸ ': ('ì¿ íŒ¡ì´ì¸ ID', 'ì¿ íŒ¡ì´ì¸ PW'),
        'ë•¡ê²¨ìš”': ('ë•¡ê²¨ìš”ID', 'ë•¡ê²¨ìš”PW'),
        'í† ë”': ('í† ë” ID', 'í† ë”PW'),
        'ë„¤ì´ë²„': ('ë„¤ì´ë²„ ID', 'ë„¤ì´ë²„ pw')
    }
    
    # ë§¤ì¥ ê¸°ë³¸ ì •ë³´ ì»¬ëŸ¼
    keep_cols = [
        'ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ', 'ë§¤ì¥ëª…', 'ì‚¬ì—…ì ë²ˆí˜¸', 'ì ì£¼ëª…', 'ë³€ê²½ë‹´ë‹¹SV', 
        'ì‹¤ì˜¤í”ˆì¼', 'ìƒì„¸ì£¼ì†Œ', 'ê´‘ì—­', 'ì‹œêµ°êµ¬', 'ìë©´ë™'
    ]
    
    # ê° ë§¤ì¥ì˜ í”Œë«í¼ë³„ ê³„ì •ì„ ë³„ë„ í–‰ìœ¼ë¡œ ìƒì„±
    rows = []
    print(f"ğŸ” Wideâ†’Long ë³€í™˜ ì‹œì‘: {len(gsheet_store_list)}ê°œ ë§¤ì¥")
    for idx, r in gsheet_store_list.iterrows():
        base = {c: r[c] for c in keep_cols}
        for platform, (id_col, pw_col) in platform_cols.items():
            uid = r.get(id_col)
            pwd = r.get(pw_col)
            # IDë‚˜ PW ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í–‰ ì¶”ê°€
            if pd.notna(uid) or pd.notna(pwd):
                rows.append({
                    **base, 
                    'í”Œë«í¼': platform, 
                    'ê³„ì •ID': uid, 
                    'ê³„ì •PW': pwd
                })
    
    print(f"ğŸ” ë³€í™˜ ê²°ê³¼: {len(rows)}ê°œ í–‰ ìƒì„±ë¨ (í”Œë«í¼ ê³„ì • ì •ë³´)")
    
    # Long í˜•ì‹ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    result_df = pd.DataFrame(rows)
    print(f"ğŸ” result_df ìƒì„±: {len(result_df)}í–‰, ì»¬ëŸ¼: {list(result_df.columns)}")
    
    # ìˆ˜ì§‘ ì‹œê°„ ì¶”ê°€
    result_df["collected_at"] = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # ì»¬ëŸ¼ëª… ë³€ê²½
    result_df.rename(columns={"ë³€ê²½ë‹´ë‹¹SV": "ë‹´ë‹¹ì"}, inplace=True)

    # ë‹´ë‹¹ì ì´ë©”ì¼ ë§¤í•‘ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
    result_df["email"] = result_df["ë‹´ë‹¹ì"].map(MANAGER_EMAIL_MAP).fillna('')
    
    # ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
    column_order = [
        'ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ', 'ë§¤ì¥ëª…', 'ì‚¬ì—…ì ë²ˆí˜¸', 'ì ì£¼ëª…', 'ë‹´ë‹¹ì',
        'ì‹¤ì˜¤í”ˆì¼', 'ìƒì„¸ì£¼ì†Œ', 'ê´‘ì—­', 'ì‹œêµ°êµ¬', 'ìë©´ë™',
        'í”Œë«í¼', 'ê³„ì •ID', 'ê³„ì •PW',
        'collected_at', 'email'
    ]
    result_df = result_df[column_order]
    
    # nan ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
    result_df = result_df.fillna('')
    
    return result_df


def fetch_and_transform_gsheet(**context):
    """êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ê°€ë§¹ì  ë°ì´í„° ì¶”ì¶œ ë° ë³€í™˜"""
    ti = context['task_instance']
    
    # 1. êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ
    print("ğŸ“¥ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    raw_df = extract_gsheet(
        url="https://docs.google.com/spreadsheets/d/1a6-20U1-FYCQEfbOOVSDG3M0q6G2me5f/edit?usp=sharing&ouid=116296472165065607173&rtpof=true&sd=true",
        sheet_name="ê°€ë§¹ì ë¦¬ìŠ¤íŠ¸",
        file_name="001_ê°€ë§¹ì ë¦¬ìŠ¤íŠ¸_250218"
    )
    print(f"âœ… ì›ë³¸ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(raw_df)}í–‰")
    
    # 2. ë°ì´í„° ë³€í™˜ (Wide â†’ Long)
    print("ğŸ”„ ë°ì´í„° ë³€í™˜ ì¤‘...")
    transformed_df = transform_gsheet_data(raw_df)
    print(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(transformed_df)}í–‰ (í”Œë«í¼ë³„ ê³„ì •)")
    
    # 3. XComì— ê²°ê³¼ ì €ì¥ (ë‹¤ìŒ íƒœìŠ¤í¬ì—ì„œ ì‚¬ìš©)
    # Timestamp ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì§ë ¬í™” ë¬¸ì œ í•´ê²°
    transformed_dict = transformed_df.copy()
    
    # datetime/Timestamp ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    for col in transformed_dict.columns:
        if transformed_dict[col].dtype == 'datetime64[ns]':
            transformed_dict[col] = transformed_dict[col].astype(str)
    
    ti.xcom_push(key='transformed_df', value=transformed_dict.to_dict('records'))
    ti.xcom_push(key='row_count', value=len(transformed_df))
    
    # 4. ì´ë©”ì¼ìš© HTML ìƒì„±
    html_preview = transformed_df.head(10).to_html(index=False, border=1)
    ti.xcom_push(key='df_html', value=html_preview)
    
    return f"ì¶”ì¶œ ë° ë³€í™˜ ì™„ë£Œ: {len(transformed_df)}í–‰"


# ============================================================
# Task 2: CSV ì €ì¥
# ============================================================

def save_to_csv(**context):
    """ë³€í™˜ëœ ë°ì´í„°ë¥¼ CSVì— ì €ì¥"""
    ti = context['task_instance']
    
    # ì´ì „ íƒœìŠ¤í¬ì—ì„œ ë³€í™˜ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    records = ti.xcom_pull(task_ids='fetch_and_transform', key='transformed_df')
    
    print(f"ğŸ” XComì—ì„œ ê°€ì ¸ì˜¨ records: {len(records) if records else 0}ê°œ")
    if records:
        print(f"ğŸ” ì²« ë²ˆì§¸ ë ˆì½”ë“œ ìƒ˜í”Œ: {records[0] if records else None}")
    
    if not records:
        print("âŒ ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
        return "ë°ì´í„° ì—†ìŒ"
    
    df = pd.DataFrame(records)
    print(f"ğŸ’¾ CSV ì €ì¥ ì¤‘... ({len(df)}í–‰)")
    print(f"ğŸ” DataFrame ì»¬ëŸ¼: {list(df.columns)}")
    print(f"ğŸ” DataFrame ìƒ˜í”Œ (ì²« 2í–‰):\n{df.head(2)}")
    
    # ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
    column_order = [
        'ì˜¤í”ˆìˆœì„œ', 'í˜¸ì ', 'ë§¤ì¥ëª…', 'ì‚¬ì—…ì ë²ˆí˜¸', 'ì ì£¼ëª…', 'ë‹´ë‹¹ì',
        'ì‹¤ì˜¤í”ˆì¼', 'ìƒì„¸ì£¼ì†Œ', 'ê´‘ì—­', 'ì‹œêµ°êµ¬', 'ìë©´ë™',
        'í”Œë«í¼', 'ê³„ì •ID', 'ê³„ì •PW',
        'collected_at', 'email'
    ]
    df = df[column_order]
    
    # ë‹´ë‹¹ìê°€ ì—†ëŠ” í–‰ ì œì™¸ (fillna ì „ì— í•„í„°ë§)
    df = df[~df["ë‹´ë‹¹ì"].isna()]
    df = df[df["ë‹´ë‹¹ì"].astype(str).str.strip() != '']
    
    # nan ê°’ ì œê±° (ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜)
    df = df.replace('nan', '')
    df = df.fillna('')
    
    # ë³µí•© í‚¤ ìƒì„±: ì‚¬ì—…ìë²ˆí˜¸ + í”Œë«í¼ + ìˆ˜ì§‘ë‚ ì§œë¡œ ê³ ìœ  í‚¤ ë§Œë“¤ê¸°
    # collected_atì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ (ì‹œê°„ ì œì™¸)
    df['collection_date'] = pd.to_datetime(df['collected_at']).dt.strftime('%Y-%m-%d')
    df['composite_key'] = df['ì‚¬ì—…ì ë²ˆí˜¸'].astype(str) + '_' + df['í”Œë«í¼'].astype(str) + '_' + df['collection_date'].astype(str)
    
    # ============================================================
    # 1. OneDriveì— ì €ì¥ (ë©”ì¸ ê²½ë¡œ) - ì•ˆì „í•œ ì“°ê¸°
    # ============================================================
    print(f"ğŸ’¾ OneDriveì— ì €ì¥ ì¤‘... ({len(df)}í–‰)")
    
    # composite_key ì»¬ëŸ¼ ì œê±° (ì €ì¥ ì‹œ ë¶ˆí•„ìš”)
    df_save = df.drop(columns=['composite_key', 'collection_date'])
    
    # OneDrive ì•ˆì „ ì €ì¥ (ì„ì‹œ íŒŒì¼ + ë™ê¸°í™” ëŒ€ê¸°)
    from modules.transform.utility.onedrive_sync import save_with_onedrive_sync
    
    save_with_onedrive_sync(
        df_save,
        ONEDRIVE_CSV_PATH,
        index=False,
        encoding='utf-8-sig'
    )
    print(f"âœ… OneDrive ì €ì¥ ì™„ë£Œ: {ONEDRIVE_CSV_PATH} ({len(df_save)}ê±´)")
    
    return f"ì €ì¥ ì™„ë£Œ: ì´ {len(df_save)}ê±´ ì €ì¥ë¨"


# ============================================================
# DAG ì„¤ì •
# ============================================================

# ============================================================
# Task 4: OneDrive ë™ê¸°í™” (Windowsë¡œ íŒŒì¼ ë³µì‚¬)
# ============================================================

def copy_to_windows_onedrive(**context):
    """Docker ë‚´ë¶€ì˜ onedrive_db íŒŒì¼ì„ Windows OneDriveë¡œ ìë™ ë³µì‚¬ (ì–‘ë°©í–¥ ë™ê¸°í™”)"""
    import subprocess
    import os
    
    print(f"ğŸ”„ Windows OneDrive ë™ê¸°í™” ì‹œì‘...")
    
    # Windowsì—ì„œ robocopyë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ëª…ë ¹ì–´
    source = r"C:\Users\ë¯¼ì¤€\doridang_airflow\onedrive_sync"
    target = r"C:\Users\ë¯¼ì¤€\OneDrive - ì£¼ì‹íšŒì‚¬ ë„ë¦¬ë‹¹\Doridang_DB"
    
    try:
        # PowerShellì„ í†µí•´ robocopy ì‹¤í–‰
        # Windows í˜¸ìŠ¤íŠ¸ì—ì„œë§Œ ì‘ë™í•˜ë¯€ë¡œ Docker ë‚´ë¶€ì—ì„œëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
        cmd = f'powershell -Command "robocopy \\"{source}\\" \\"{target}\\" /MIR /MT:8 /R:3 /W:5"'
        
        print(f"ğŸ“‚ ì›ë³¸ (ë¡œì»¬): {source}")
        print(f"ğŸ“‚ ëŒ€ìƒ (OneDrive): {target}")
        print(f"â³ robocopy ì‹¤í–‰ ì¤‘...")
        
        # Docker ë‚´ë¶€ì—ì„œ Windows í˜¸ìŠ¤íŠ¸ ëª…ë ¹ì„ ì§ì ‘ ì‹¤í–‰í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ
        # í˜¸ìŠ¤íŠ¸ì—ì„œ ë³„ë„ë¡œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ì•¼ í•¨
        print(f"âš ï¸  ì£¼ì˜: ì´ DAGì€ Docker ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰ ì¤‘ì´ë¯€ë¡œ Windows ëª…ë ¹ì„ ì§ì ‘ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"âœ… í•´ê²°ì±…: í˜¸ìŠ¤íŠ¸ Windowsì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print(f"   robocopy \"{source}\" \"{target}\" /MIR /MT:8")
        
        return "íŒŒì¼ ë™ê¸°í™” ì¤€ë¹„ ì™„ë£Œ. í˜¸ìŠ¤íŠ¸ì—ì„œ robocopy ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í•„ìš”"
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"


# ============================================================
# ì´ë©”ì¼ ìˆ˜ì‹ ì
# ============================================================
TO_MEMBERS = ['a17019@kakao.com']


with DAG(
    dag_id=filename.replace('.py', ''),
    description='êµ¬ê¸€ì‹œíŠ¸ ê°€ë§¹ì  ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ â†’ ë³€í™˜ â†’ OneDrive ì €ì¥',
    schedule="31 6 * * *",  # ë§¤ì¼ 06:31 ì‹¤í–‰
    start_date=pendulum.datetime(2025, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=['gsheet', 'store', 'etl'],
) as dag:
    
    # Task 1: êµ¬ê¸€ì‹œíŠ¸ ì¶”ì¶œ ë° ë³€í™˜
    fetch_task = PythonOperator(
        task_id="fetch_and_transform",
        python_callable=fetch_and_transform_gsheet,
    )
    
    # Task 2: CSV ì €ì¥ (downloads í´ë”)
    save_task = PythonOperator(
        task_id='save_to_csv',
        python_callable=save_to_csv,
    )
    
    # Task 3: ì´ë©”ì¼ ì•Œë¦¼ (í™˜ê²½ë³€ìˆ˜ SMTP Connection ì‚¬ìš©)
    email_task = EmailOperator(
        task_id='send_email_notification',
        conn_id='conn_smtp_gmail',
        to=TO_MEMBERS,
        subject='[ë„ë¦¬ë‹¹] ê°€ë§¹ì  ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ',
        html_content="""<html>
<body>
<h3>ğŸ“Š ê°€ë§¹ì  ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ</h3>
<p><strong>ì²˜ë¦¬ í–‰ ìˆ˜:</strong> {{ task_instance.xcom_pull(task_ids='fetch_and_transform', key='row_count') }}í–‰</p>
<p><strong>ì €ì¥ ìœ„ì¹˜:</strong> OneDrive/Doridang_DB/sales_employee.csv</p>
<p style="color: #666; font-size: 12px;">(ë°±ì—…: /opt/airflow/downloads/sales_employee.csv)</p>

<h4>ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ê°œ):</h4>
{{ task_instance.xcom_pull(task_ids='fetch_and_transform', key='df_html') }}

<p style="color: #666; font-size: 12px; margin-top: 20px;">
ì‹¤í–‰ ì‹œê°„: {{ ts }}<br/>
DAG: {{ dag.dag_id }}
</p>
</body>
</html>""",
    )
    
    # Task 4: ìœˆë„ìš° OneDriveì— ë³µì‚¬
    copy_task = PythonOperator(
        task_id='copy_to_onedrive',
        python_callable=copy_to_windows_onedrive,
    )
    
    # Task ì˜ì¡´ì„± ì„¤ì •: ì¶”ì¶œâ†’ë³€í™˜ â†’ CSVì €ì¥ â†’ ìœˆë„ìš°ë³µì‚¬ â†’ ì´ë©”ì¼
    fetch_task >> save_task >> copy_task >> email_task

