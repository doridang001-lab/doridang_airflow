# dags/relay_cs_crawling_fdam.py

"""
Relay FMS ë§¤ì¥CS í¬ë¡¤ë§ DAG
- ë¡œê·¸ì¸ â†’ ì„œë²„ ì¶”ê°€ â†’ í¬ë¡¤ë§ â†’ ë¡œì»¬ DB ì €ì¥ â†’ OneDrive ë°±ì—…
"""

import os
import sys
from pathlib import Path
import shutil
from datetime import datetime

import pandas as pd
import pendulum
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.smtp.operators.smtp import EmailOperator

# modules ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from modules.extract.crawling_relay_cs_fdam import run_relay_cs_crawling

# í˜„ì¬ íŒŒì¼ëª… (DAG IDë¡œ ì‚¬ìš©)
filename = os.path.basename(__file__)

# ========== ì„¤ì • ==========
RELAY_ID = "ì¡°ë¯¼ì¤€"
RELAY_PW = "1234"
SERVER_NAME = "ë„ë¦¬ë‹¹"
SERVER_NUMBER = "10625"

# ë¡œì»¬ DB ê²½ë¡œ (ì»¨í…Œì´ë„ˆ ì•ˆ)
LOCAL_CSV = Path("/opt/airflow/Doridang/ë¬¸ì˜_DB/relay_cs.csv")

# OneDrive ë°±ì—… ê²½ë¡œ
ONEDRIVE_BACKUP = Path("/opt/airflow/onedrive_backup/ë¬¸ì˜_DB")

to_members = ['a17019@kakao.com']


# ============================================================
# ì €ì¥ í•¨ìˆ˜
# ============================================================
def save_relay_cs_to_csv(
    df: pd.DataFrame,
    local_csv_path: Path,
    onedrive_backup_path: Path,
    duplicate_subset: list = None
) -> dict:
    """
    Relay CS ë°ì´í„°ë¥¼ ë¡œì»¬ CSVì— ì €ì¥í•˜ê³  OneDriveë¡œ ë°±ì—…
    """
    if duplicate_subset is None:
        duplicate_subset = ['ì ‘ìˆ˜_ì ‘ìˆ˜ë²ˆí˜¸']
    
    try:
        local_csv_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ì¡´ CSV ë¡œë“œ ë° ë³‘í•©
        if local_csv_path.exists():
            existing_df = pd.read_csv(local_csv_path, encoding='utf-8-sig')
            print(f"ğŸ“ ê¸°ì¡´ ë°ì´í„°: {len(existing_df)}ê±´")
            
            merged_df = pd.concat([existing_df, df], ignore_index=True)
            merged_df = merged_df.drop_duplicates(subset=duplicate_subset, keep='last')
            
            new_count = len(merged_df) - len(existing_df)
            print(f"âœ… ì‹ ê·œ ë°ì´í„°: {new_count}ê±´")
            
        else:
            merged_df = df
            new_count = len(df)
            print(f"âœ… ì‹ ê·œ íŒŒì¼ ìƒì„±: {new_count}ê±´")
        
        # ë¡œì»¬ CSV ì €ì¥
        merged_df.to_csv(local_csv_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {local_csv_path}")
        
        # OneDrive ë°±ì—…
        onedrive_backup_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = onedrive_backup_path / f"backup_{timestamp}_relay_cs.csv"
        
        shutil.copy2(local_csv_path, backup_file)
        print(f"â˜ï¸ OneDrive ë°±ì—… ì™„ë£Œ: {backup_file.name}")
        
        # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (ìµœê·¼ 20ê°œë§Œ)
        backups = sorted(onedrive_backup_path.glob("backup_*.csv"))
        if len(backups) > 20:
            for old_backup in backups[:-20]:
                old_backup.unlink()
                print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {old_backup.name}")
        
        return {
            'success': True,
            'total': len(merged_df),
            'new': new_count,
            'message': f'ì €ì¥ ì™„ë£Œ: ì´ {len(merged_df)}ê±´ (ì‹ ê·œ {new_count}ê±´)'
        }
        
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return {
            'success': False,
            'error': str(e),
            'message': f'ì €ì¥ ì‹¤íŒ¨: {e}'
        }


# ============================================================
# Task 1: í¬ë¡¤ë§
# ============================================================
def crawl_relay_cs(**context):
    """Relay FMS ë§¤ì¥CS í¬ë¡¤ë§ ì‹¤í–‰"""
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    result_df = run_relay_cs_crawling(
        user_id=RELAY_ID,
        password=RELAY_PW,
        headless=True,
        server_name=SERVER_NAME,
        server_number=SERVER_NUMBER
    )
    
    # XComì— DataFrame ì €ì¥
    context['task_instance'].xcom_push(key='df_json', value=result_df.to_json())
    
    print(f"í¬ë¡¤ë§ ì™„ë£Œ: {len(result_df)}ê±´")
    return f"í¬ë¡¤ë§ ì™„ë£Œ: {len(result_df)}ê±´"


# ============================================================
# Task 2: CSV ì €ì¥ ë° ë°±ì—…
# ============================================================
def save_relay_cs(**context):
    """í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ë¡œì»¬ CSVì— ì €ì¥í•˜ê³  OneDrive ë°±ì—…"""
    ti = context['task_instance']
    df_json = ti.xcom_pull(task_ids='crawl_task', key='df_json')
    
    if not df_json:
        print("âŒ í¬ë¡¤ë§ ë°ì´í„° ì—†ìŒ")
        return "ì €ì¥ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ"
    
    # JSON â†’ DataFrame
    df = pd.read_json(df_json)
    
    if df.empty:
        print("âŒ DataFrameì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        return "ì €ì¥ ì‹¤íŒ¨: ë¹ˆ DataFrame"
    
    # CSV ì €ì¥ ë° ë°±ì—…
    result = save_relay_cs_to_csv(
        df=df,
        local_csv_path=LOCAL_CSV,
        onedrive_backup_path=ONEDRIVE_BACKUP,
        duplicate_subset=['ì ‘ìˆ˜_ì ‘ìˆ˜ë²ˆí˜¸']
    )
    
    return result.get("message", "ì €ì¥ ì™„ë£Œ")


# ============================================================
# DAG ì •ì˜
# ============================================================
with DAG(
    dag_id=filename.replace('.py', ''),
    schedule="0 9 * * *",  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ
    start_date=pendulum.datetime(2026, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    max_active_runs=1,
    tags=['crawling', 'relay', 'cs', 'fdam']
) as dag:
    
    # Task 1: í¬ë¡¤ë§
    crawl_task = PythonOperator(
        task_id='crawl_task',
        python_callable=crawl_relay_cs,
    )
    
    # Task 2: CSV ì €ì¥
    save_task = PythonOperator(
        task_id='save_task',
        python_callable=save_relay_cs,
    )
    
    # Task 3: ì´ë©”ì¼ ì•Œë¦¼
    email_task = EmailOperator(
        task_id='send_email_task',
        conn_id='conn_smtp_gmail',
        to=to_members,
        subject='[Relay CS] í¬ë¡¤ë§ ì™„ë£Œ',
        html_content="""
        <html>
            <body>
                <h3>âœ… Relay FMS ë§¤ì¥CS í¬ë¡¤ë§ ì™„ë£Œ</h3>
                <p><strong>ìˆ˜ì§‘ ê²°ê³¼:</strong></p>
                <pre>{{ task_instance.xcom_pull(task_ids='crawl_task', key='return_value') }}</pre>
                
                <p><strong>ì €ì¥ ê²°ê³¼:</strong></p>
                <pre>{{ task_instance.xcom_pull(task_ids='save_task', key='return_value') }}</pre>
                
                <hr>
                <p style="color: gray; font-size: 12px;">
                    ì‹¤í–‰ ì‹œê°„: {{ ts }}<br>
                    DAG ID: {{ dag.dag_id }}
                </p>
            </body>
        </html>
        """,
    )
    
    # Task ì˜ì¡´ì„±
    crawl_task >> save_task >> email_task